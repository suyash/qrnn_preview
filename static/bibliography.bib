@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  year={2019}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{bradbury2016quasi,
  title={Quasi-recurrent neural networks},
  author={Bradbury, James and Merity, Stephen and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1611.01576},
  year={2016}
}

@misc{karpathy2015effectiveness,
  title={The Unreasonable Effectiveness of Recurrent Neural Networks},
  author={Karpathy, Andrej},
  year={2015},
  url={https://karpathy.github.io/2015/05/21/rnn-effectiveness/},
}

@article{karpathy2015visualizing,
  title={Visualizing and understanding recurrent networks},
  author={Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li},
  journal={arXiv preprint arXiv:1506.02078},
  year={2015}
}

@misc{olah2015understanding,
 title={Understanding LSTM Networks},
 author={Olah, Christopher},
 year={2015},
 url={http://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013},
  url={https://arxiv.org/pdf/1308.0850v5.pdf}
}

@article{araujo2019computing,
  author = {Araujo, Andr√© and Norris, Wade and Sim, Jack},
  title = {Computing Receptive Fields of Convolutional Neural Networks},
  journal = {Distill},
  year = {2019},
  note = {https://distill.pub/2019/computing-receptive-fields},
  doi = {10.23915/distill.00021}
}

@article{madsen2019visualizing,
  author = {Madsen, Andreas},
  title = {Visualizing memorization in RNNs},
  journal = {Distill},
  year = {2019},
  note = {https://distill.pub/2019/memorization-in-rnns},
  doi = {10.23915/distill.00016}
}

@article{dumoulin2016learned,
  title={A learned representation for artistic style},
  author={Dumoulin, Vincent and Shlens, Jonathon and Kudlur, Manjunath},
  journal={arXiv preprint arXiv:1610.07629},
  year={2016}
}

@article{krueger2016zoneout,
  title={Zoneout: Regularizing rnns by randomly preserving hidden activations},
  author={Krueger, David and Maharaj, Tegan and Kram{\'a}r, J{\'a}nos and Pezeshki, Mohammad and Ballas, Nicolas and Ke, Nan Rosemary and Goyal, Anirudh and Bengio, Yoshua and Courville, Aaron and Pal, Chris},
  journal={arXiv preprint arXiv:1606.01305},
  year={2016}
}

@article{murdoch2018beyond,
  title={Beyond word importance: Contextual decomposition to extract interactions from LSTMs},
  author={Murdoch, W James and Liu, Peter J and Yu, Bin},
  journal={arXiv preprint arXiv:1801.05453},
  year={2018}
}

@inproceedings{singh2018hierarchical,
  title={Hierarchical interpretations for neural network predictions},
  author={Chandan Singh and W. James Murdoch and Bin Yu},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=SkEqro0ctQ},
}

@article{carter2016experiments,
  author = {Carter, Shan and Ha, David and Johnson, Ian and Olah, Chris},
  title = {Experiments in Handwriting with a Neural Network},
  journal = {Distill},
  year = {2016},
  url = {http://distill.pub/2016/handwriting},
  doi = {10.23915/distill.00004}
}

@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013}
}
